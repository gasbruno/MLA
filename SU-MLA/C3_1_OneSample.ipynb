{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd4fd92a",
   "metadata": {},
   "source": [
    "# Practical work 3 : MLP, part 1\n",
    "\n",
    "## Building 2 layers MLP from its graph\n",
    "\n",
    "Dans ce Notebook, on propose de réaliser le graphe d'une architecture de réseau de neurones MLP à une couche cachée en utilisant les opérateurs du graphe tels qu'ils sont définis dans la bibliothèque `op`. \n",
    "\n",
    "* Définir le modèle en déclarant tous les opérateurs nécessaires à sa réalisation\n",
    "* Afficher la valeur des poids\n",
    "* Réaliser une prédiction (forward) sur l'exemple donné et afficher l'erreur (valeur du coût quadratique sur l'exemple)\n",
    "* Réaliser une optmisation sur un pas (backward)\n",
    "* Mettre à jour les poids avec un pas fixe\n",
    "* Réaliser une nouvelle prédiction sur le même exemple et afficher la nouvelle erreur obtenue\n",
    "* Que constatez-vous ? Rejouez la simulation pour différentes valeurs du pas fixe. \n",
    "\n",
    "Schéma du réseau à réaliser:\n",
    "\n",
    "<img src=\"./MLP2-a.jpg\" width=\"400\" align=\"center\"/>\n",
    "\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48017766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import op"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384d98f1",
   "metadata": {},
   "source": [
    "## Metaparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73339b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a101a6",
   "metadata": {},
   "source": [
    "## Inputs / outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aebf4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operator -> PlaceHolder\n",
      "Operator -> PlaceHolder\n",
      "Operator -> PlaceHolder\n",
      "Operator -> PlaceHolder\n"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "x1 = op.PlaceHolder(1.0)\n",
    "x2 = op.PlaceHolder(-1)\n",
    "\n",
    "# Desired outputs\n",
    "y2_1 = op.PlaceHolder(0)\n",
    "y2_2 = op.PlaceHolder(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace588fb",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2cad0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operator -> Mul\n",
      "Operator -> Mul\n",
      "Operator -> Add\n",
      "Operator -> Add\n",
      "Operator -> Tanh\n",
      "Operator -> Mul\n",
      "Operator -> Mul\n",
      "Operator -> Add\n",
      "Operator -> Add\n",
      "Operator -> Tanh\n",
      "Operator -> Mul\n",
      "Operator -> Mul\n",
      "Operator -> Add\n",
      "Operator -> Add\n",
      "Operator -> Tanh\n",
      "Operator -> Mul\n",
      "Operator -> Mul\n",
      "Operator -> Add\n",
      "Operator -> Add\n",
      "Operator -> Tanh\n"
     ]
    }
   ],
   "source": [
    "# Layer 1 - Neuron 1\n",
    "w1_11 = op.Parameter(-1)\n",
    "w1_12 = op.Parameter(2)\n",
    "mul1_11 = op.Mul()\n",
    "mul1_12 = op.Mul()\n",
    "add1_11 = op.Add()\n",
    "b1_1 = op.Parameter(4)\n",
    "add1_12 = op.Add()\n",
    "sigma1_1 = op.Tanh()\n",
    "\n",
    "# Layer 1 - Neuron 2\n",
    "w1_21 = op.Parameter(-1)\n",
    "w1_22 = op.Parameter(1)\n",
    "mul1_21 = op.Mul()\n",
    "mul1_22 = op.Mul()\n",
    "add1_21 = op.Add()\n",
    "b1_2 = op.Parameter(-1)\n",
    "add1_22 = op.Add()\n",
    "sigma1_2 = op.Tanh()\n",
    "\n",
    "# Layer 2 - Neuron 1\n",
    "w2_11 = op.Parameter(-1)\n",
    "w2_12 = op.Parameter(2)\n",
    "mul2_11 = op.Mul()\n",
    "mul2_12 = op.Mul()\n",
    "add2_11 = op.Add()\n",
    "b2_1 = op.Parameter(4)\n",
    "add2_12 = op.Add()\n",
    "sigma2_1 = op.Tanh()\n",
    "\n",
    "# Layer 2 - Neuron 2\n",
    "w2_21 = op.Parameter(-1)\n",
    "w2_22 = op.Parameter(1)\n",
    "mul2_21 = op.Mul()\n",
    "mul2_22 = op.Mul()\n",
    "add2_21 = op.Add()\n",
    "b2_2 = op.Parameter(-1)\n",
    "add2_22 = op.Add()\n",
    "sigma2_2 = op.Tanh()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36631b89",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7768862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operator -> Sub\n",
      "Operator -> Sub\n",
      "Operator -> Square\n",
      "Operator -> Square\n",
      "Operator -> Add\n"
     ]
    }
   ],
   "source": [
    "err1 = op.Sub()\n",
    "err2 = op.Sub()\n",
    "mse1 = op.Square()\n",
    "mse2 = op.Square()\n",
    "mseT = op.Add()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0835ab2",
   "metadata": {},
   "source": [
    "## Display weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ec4bac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- First layer -----\n",
      "w1__11: -1\n",
      "w1__12: 2\n",
      "b1__1: 4\n",
      "w1__21: -1\n",
      "w1__22: 1\n",
      "b1__2: -1\n",
      "----- Second layer -----\n",
      "w2__11: -1\n",
      "w2__12: 2\n",
      "b2__1: 4\n",
      "w2__21: -1\n",
      "w2__22: 1\n",
      "b2__2: -1\n"
     ]
    }
   ],
   "source": [
    "def display_weights():\n",
    "    print(\"----- First layer -----\")\n",
    "    print(\"w1__11:\", w1_11())\n",
    "    print(\"w1__12:\", w1_12())\n",
    "    print(\"b1__1:\", b1_1())\n",
    "    print(\"w1__21:\", w1_21())\n",
    "    print(\"w1__22:\", w1_22())\n",
    "    print(\"b1__2:\", b1_2())\n",
    "\n",
    "    print(\"----- Second layer -----\")\n",
    "    print(\"w2__11:\", w2_11())\n",
    "    print(\"w2__12:\", w2_12())\n",
    "    print(\"b2__1:\", b2_1())\n",
    "    print(\"w2__21:\", w2_21())\n",
    "    print(\"w2__22:\", w2_22())\n",
    "    print(\"b2__2:\", b2_2())\n",
    "\n",
    "display_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a0d922",
   "metadata": {},
   "source": [
    "## Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c5260d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Layer 1 neuron 1\n",
    "e1_11 = mul1_11(x1(), w1_11())\n",
    "e1_12 = mul1_12(x2(), w1_12())\n",
    "v1_10 = add1_11(e1_11, e1_12)\n",
    "v1_1 = add1_12(v1_10, b1_1())\n",
    "y1_1 = sigma1_1(v1_1)\n",
    "\n",
    "# Forward Layer 1 neuron 2\n",
    "e1_21 = mul1_21(x1(), w1_21())\n",
    "e1_22 = mul1_22(x2(), w1_22())\n",
    "v1_20 = add1_21(e1_21, e1_22)\n",
    "v1_2 = add1_22(v1_20, b1_2())\n",
    "y1_2 = sigma1_2(v1_2)\n",
    "\n",
    "# Forward Layer 2 neuron 1\n",
    "e2_11 = mul2_11(y1_1, w2_11())\n",
    "e2_12 = mul2_12(y1_2, w2_12())\n",
    "v2_10 = add2_11(e2_11, e2_12)\n",
    "v2_1 = add2_12(v2_10, b2_1())\n",
    "ypred_1 = sigma2_1(v2_1)\n",
    "\n",
    "# Forward Layer 2 neuron 2\n",
    "e2_21 = mul2_21(y1_1, w2_21())\n",
    "e2_22 = mul2_22(y1_2, w2_22())\n",
    "v2_20 = add2_21(e2_21, e2_22)\n",
    "v2_2 = add2_22(v2_20, b2_2())\n",
    "ypred_2 = sigma2_2(v2_2)\n",
    "\n",
    "# Error\n",
    "error1 = err1(ypred_1, y2_1()) \n",
    "error2 = err2(ypred_2, y2_2())\n",
    "mserror1 = mse1(error1)\n",
    "mserror2 = mse2(error2) \n",
    "L = mseT(mserror1, mserror2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed640643",
   "metadata": {},
   "source": [
    "## Display outputs and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cc54cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 - Neuron 1 Output: 0.7615941559557649\n",
      "Layer 1 - Neuron 2 Output: -0.9950547536867305\n",
      "Layer 2 - Neuron 1 Output: 0.8478052164832094\n",
      "Layer 2 - Neuron 2 Output: -0.9919668240197789\n",
      "Loss: 4.686705513091586\n"
     ]
    }
   ],
   "source": [
    "# Display output\n",
    "def display_outputs_and_loss():\n",
    "    print(\"Layer 1 - Neuron 1 Output:\", y1_1)\n",
    "    print(\"Layer 1 - Neuron 2 Output:\", y1_2)\n",
    "    print(\"Layer 2 - Neuron 1 Output:\", ypred_1)\n",
    "    print(\"Layer 2 - Neuron 2 Output:\", ypred_2)\n",
    "    print(\"Loss:\", L)\n",
    "    \n",
    "display_outputs_and_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2e9e3b",
   "metadata": {},
   "source": [
    "## Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "812d9f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_L = 1\n",
    "\n",
    "# Backward Layer 2 neuron 1\n",
    "g_mserror1 = mseT.grad1(g_L)\n",
    "g_error1 = mse1.grad(g_mserror1)\n",
    "g_ypred_1 = err1.grad1(g_error1)\n",
    "g_v2_1 = sigma2_1.grad(g_ypred_1)\n",
    "g_v2_10 = add2_12.grad1(g_v2_1)\n",
    "g_b2_1 = add2_12.grad2(g_v2_1)\n",
    "g_e2_11 = mul2_11.grad1(g_v2_10)\n",
    "g_w2_11 = mul2_11.grad2(g_v2_10)\n",
    "g_e2_12 = mul2_12.grad1(g_v2_10)\n",
    "g_w2_12 = mul2_12.grad2(g_v2_10)\n",
    "\n",
    "# Backward Layer 2 neuron 2\n",
    "g_mserror2 = mseT.grad2(g_L)\n",
    "g_error2 = mse2.grad(g_mserror2)\n",
    "g_ypred_2 = err2.grad1(g_error2)\n",
    "g_v2_2 = sigma2_2.grad(g_ypred_2)\n",
    "g_v2_20 = add2_22.grad1(g_v2_2)\n",
    "g_b2_2 = add2_22.grad2(g_v2_2)\n",
    "g_e2_21 = mul2_21.grad1(g_v2_20)\n",
    "g_w2_21 = mul2_21.grad2(g_v2_20)\n",
    "g_e2_22 = mul2_22.grad1(g_v2_20)\n",
    "g_w2_22 = mul2_22.grad2(g_v2_20)\n",
    "\n",
    "# Backward Layer 1 neuron 1\n",
    "g_v1_1 = sigma1_1.grad(g_e2_11 + g_e2_21)\n",
    "g_v1_10 = add1_12.grad1(g_v1_1)\n",
    "g_b1_1 = add1_12.grad2(g_v1_1)\n",
    "g_w1_11 = mul1_11.grad2(g_v1_10)\n",
    "g_w1_12 = mul1_12.grad2(g_v1_10)\n",
    "\n",
    "# Backward Layer 1 neuron 2\n",
    "g_v1_2 = sigma1_2.grad(g_e2_12 + g_e2_22)\n",
    "g_v1_20 = add1_22.grad1(g_v1_2)\n",
    "g_b1_2 = add1_22.grad2(g_v1_2)\n",
    "g_w1_21 = mul1_21.grad2(g_v1_20)\n",
    "g_w1_22 = mul1_22.grad2(g_v1_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4a1615",
   "metadata": {},
   "source": [
    "## Display gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca79ab57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Gradients -----\n",
      "dL/dw2_11: 0.3631663816211469\n",
      "dL/dw2_12: -0.47449213151830005\n",
      "dL/db2_1: 0.47685027357568177\n",
      "dL/dw2_21: -0.048551771614707674\n",
      "dL/dw2_22: 0.06343492891499208\n",
      "dL/db2_2: -0.06375018930361602\n",
      "dL/dw1_11: -0.1734914359128595\n",
      "dL/dw1_12: 0.1734914359128595\n",
      "dL/db1_1: -0.1734914359128595\n",
      "dL/dw1_21: 0.008780283305922693\n",
      "dL/dw1_22: -0.008780283305922693\n",
      "dL/db1_2: 0.008780283305922693\n"
     ]
    }
   ],
   "source": [
    "def display_gradients():\n",
    "    print(\"----- Gradients -----\")\n",
    "    print(\"dL/dw2_11:\", g_w2_11)\n",
    "    print(\"dL/dw2_12:\", g_w2_12)\n",
    "    print(\"dL/db2_1:\", g_b2_1)\n",
    "    print(\"dL/dw2_21:\", g_w2_21)\n",
    "    print(\"dL/dw2_22:\", g_w2_22)\n",
    "    print(\"dL/db2_2:\", g_b2_2)\n",
    "    print(\"dL/dw1_11:\", g_w1_11)\n",
    "    print(\"dL/dw1_12:\", g_w1_12)\n",
    "    print(\"dL/db1_1:\", g_b1_1)\n",
    "    print(\"dL/dw1_21:\", g_w1_21)\n",
    "    print(\"dL/dw1_22:\", g_w1_22)\n",
    "    print(\"dL/db1_2:\", g_b1_2)\n",
    "\n",
    "display_gradients()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a623e1c5",
   "metadata": {},
   "source": [
    "## weights update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03b94802",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2_11.update(w2_11() - lr * g_w2_11)\n",
    "w2_12.update(w2_12() - lr * g_w2_12)\n",
    "b2_1.update(b2_1() - lr * g_b2_1)\n",
    "w2_21.update(w2_21() - lr * g_w2_21)\n",
    "w2_22.update(w2_22() - lr * g_w2_22)\n",
    "b2_2.update(b2_2() - lr * g_b2_2)\n",
    "w1_11.update(w1_11() - lr * g_w1_11)\n",
    "w1_12.update(w1_12() - lr * g_w1_12)\n",
    "b1_1.update(b1_1() - lr * g_b1_1)\n",
    "w1_21.update(w1_21() - lr * g_w1_21)\n",
    "w1_22.update(w1_22() - lr * g_w1_22)\n",
    "b1_2.update(b1_2() - lr * g_b1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371003d9",
   "metadata": {},
   "source": [
    "## Display new weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f3aa37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- First layer -----\n",
      "w1__11: -0.9982650856408714\n",
      "w1__12: 1.9982650856408715\n",
      "b1__1: 4.001734914359129\n",
      "w1__21: -1.0000878028330593\n",
      "w1__22: 1.0000878028330593\n",
      "b1__2: -1.0000878028330593\n",
      "----- Second layer -----\n",
      "w2__11: -1.0036316638162115\n",
      "w2__12: 2.004744921315183\n",
      "b2__1: 3.995231497264243\n",
      "w2__21: -0.999514482283853\n",
      "w2__22: 0.99936565071085\n",
      "b2__2: -0.9993624981069639\n"
     ]
    }
   ],
   "source": [
    "display_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f28421",
   "metadata": {},
   "source": [
    "## New loss estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6642df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save initial loss \n",
    "L0 = L\n",
    "\n",
    "# Forward Layer 1 neuron 1\n",
    "e1_11 = mul1_11(x1(), w1_11())\n",
    "e1_12 = mul1_12(x2(), w1_12())\n",
    "v1_10 = add1_11(e1_11, e1_12)\n",
    "v1_1 = add1_12(v1_10, b1_1())\n",
    "y1_1 = sigma1_1(v1_1)\n",
    "\n",
    "# Forward Layer 1 neuron 2\n",
    "e1_21 = mul1_21(x1(), w1_21())\n",
    "e1_22 = mul1_22(x2(), w1_22())\n",
    "v1_20 = add1_21(e1_21, e1_22)\n",
    "v1_2 = add1_22(v1_20, b1_2())\n",
    "y1_2 = sigma1_2(v1_2)\n",
    "\n",
    "# Forward Layer 2 neuron 1\n",
    "e2_11 = mul2_11(y1_1, w2_11())\n",
    "e2_12 = mul2_12(y1_2, w2_12())\n",
    "v2_10 = add2_11(e2_11, e2_12)\n",
    "v2_1 = add2_12(v2_10, b2_1())\n",
    "ypred_1 = sigma2_1(v2_1)\n",
    "\n",
    "# Forward Layer 2 neuron 2\n",
    "e2_21 = mul2_21(y1_1, w2_21())\n",
    "e2_22 = mul2_22(y1_2, w2_22())\n",
    "v2_20 = add2_21(e2_21, e2_22)\n",
    "v2_2 = add2_22(v2_20, b2_2())\n",
    "ypred_2 = sigma2_2(v2_2)\n",
    "\n",
    "# Error\n",
    "error1 = err1(ypred_1, y2_1()) \n",
    "error2 = err2(ypred_2, y2_2())\n",
    "mserror1 = mse1(error1)\n",
    "mserror2 = mse2(error2) \n",
    "L = mseT(mserror1, mserror2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12892506",
   "metadata": {},
   "source": [
    "## Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0aef2a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Initial Loss -----\n",
      "Loss: 4.686705513091586\n",
      "----- After one step of training -----\n",
      "Loss: 4.679783282987222\n"
     ]
    }
   ],
   "source": [
    "print(\"----- Initial Loss -----\")\n",
    "print(\"Loss:\", L0)\n",
    "print(\"----- After one step of training -----\")\n",
    "print(\"Loss:\", L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a325f198",
   "metadata": {},
   "source": [
    "## Try it for different values of the learning rate (lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
